{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "21830c4b-3f47-4a7f-9697-95c05419871d",
    "_uuid": "6d170584ce2dcc8ddc7d555c52e00c637810bd42"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af8bd5b75a3e4d5530789479f988d566e7b85c76"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tnrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0aa7d1cd-9c1e-494d-a5a1-56e7d8f6ffca",
    "_uuid": "dbfd497e8ca31e01cb32a8e395be7568f2c8b64b"
   },
   "outputs": [],
   "source": [
    "# Ensure results are reproducable\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d30be58-4dde-4da9-9cc5-4b2290c48cb4",
    "_uuid": "1655872712ea6447b0423a3b80b0fedd8f528bee"
   },
   "outputs": [],
   "source": [
    "def mnist_load_data(path='mnist.npz'):\n",
    "    with np.load(path) as f:\n",
    "        x_train, y_train = f['x_train'], f['y_train']\n",
    "        x_test, y_test = f['x_test'], f['y_test']\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "        \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist_load_data(path='../input/mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f94f9e7fec7fb5d166b23d4fc26b4cae7d8eb252"
   },
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train,1)\n",
    "X_test = np.expand_dims(X_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af80a06b1d4b96ae07ed566b4f12fa78e9da09ab"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea321c0d595a3bad2a6cf2c57d92192e56ab1769"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = resample(X_train,y_train,n_samples=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9531958425ae5845c7915cf9d05d57c3ac9430ef"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05c41bcd93b0141d38e7c95ca3ae90d9f27baa53"
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d57d4f9fe81c6e7ed13979a7e4b2e3dac8f4666d"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import LeakyReLU, Reshape\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b92a416a2c2d0a79ae745edfb830c052874bfaff"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12d24ca183711b35cc87d5d7922d26177e9e4b60"
   },
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b3bf51b9365d356a5021c2fc2bf5df9578b2d97"
   },
   "outputs": [],
   "source": [
    "generator = Sequential() #1 \n",
    "\n",
    "generator.add(Dense(128*7*7, \n",
    "                    input_dim=latent_dim, \n",
    "                    kernel_initializer=RandomNormal(stddev=0.02))) #2\n",
    "\n",
    "generator.add(LeakyReLU(0.2)) #3\n",
    "generator.add(Reshape((128, 7, 7))) #4\n",
    "generator.add(UpSampling2D(size=(2, 2))) #5\n",
    "\n",
    "generator.add(Conv2D(64,kernel_size=(5, 5),padding='same')) #6\n",
    "\n",
    "generator.add(LeakyReLU(0.2)) #7\n",
    "generator.add(UpSampling2D(size=(2, 2))) #8\n",
    "\n",
    "generator.add(Conv2D(1, kernel_size=(5, 5),\n",
    "                        padding='same', \n",
    "                        activation='tanh')) #9\n",
    "  \n",
    "adam = Adam(lr=0.0002, beta_1=0.5)                      \n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam) #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58047ba162c42550af417713630f699f6530ceeb"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d901e7c56345597e4e00d29f891bf60c7d47912"
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=(5, 5), \n",
    "                         strides=(2, 2), \n",
    "                         padding='same', \n",
    "                         input_shape=(1, 28, 28),\n",
    "                         kernel_initializer=RandomNormal(stddev=0.02))) #1\n",
    "\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=(5, 5), \n",
    "                         strides=(2, 2), \n",
    "                         padding='same'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3)) #2\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63e44f4b620c90311cb4b533052b984804b55415"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ec9b02889c0e09508ede2cf6528fbf793c340ab"
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False #1\n",
    "ganInput = Input(shape=(latent_dim,)) #2\n",
    "x = generator(ganInput) #3\n",
    "ganOutput = discriminator(x) #4\n",
    "gan = Model(inputs=ganInput, outputs=ganOutput) #5\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam) #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a5c24f23149ef0cbcf7597790fa85fc3f30a01c"
   },
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1e4bd889178d1c553ca78ccfd96655933879acf"
   },
   "outputs": [],
   "source": [
    "def show_gen():\n",
    "    r, c = 2, 2\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    print(gen_imgs.shape)\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 1\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, 0,:,:], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    #fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "    plt.show()\n",
    "    return gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e79ad4e351cc2e0a4d4e1b14080cafde5373754"
   },
   "outputs": [],
   "source": [
    "i = show_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3cc32d8d41db8a0b3348f584a63c2854203055bc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dLosses = []\n",
    "gLosses = []\n",
    "epochs=50 \n",
    "batchSize=128\n",
    "batchCount = X_train.shape[0] // batchSize #1\n",
    "\n",
    "for e in range(1, epochs+1): #2\n",
    "    print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "    dloss = 0\n",
    "    gloss = 0\n",
    "    for _ in range(batchCount): #3      \n",
    "        noise = np.random.normal(0, 1, size=[batchSize, latent_dim]) #4\n",
    "        imageBatch = X_train[np.random.randint(0, \n",
    "                                              X_train.shape[0],\n",
    "                                              size=batchSize)] #5\n",
    "\n",
    "        generatedImages = generator.predict(noise) #6\n",
    "        X = np.concatenate([imageBatch, generatedImages]) #7\n",
    "\n",
    "        yDis = np.zeros(2*batchSize) #8\n",
    "        yDis[:batchSize] = 0.9 \n",
    "        \n",
    "        labelNoise = np.random.random(yDis.shape) #9\n",
    "        yDis += 0.05 * labelNoise + 0.05\n",
    "\n",
    "        \n",
    "        discriminator.trainable = True #10\n",
    "        dloss += discriminator.train_on_batch(X, yDis) #11\n",
    "\n",
    "        \n",
    "        noise = np.random.normal(0, 1, size=[batchSize, latent_dim]) #12\n",
    "        yGen = np.ones(batchSize) #13\n",
    "        discriminator.trainable = False #14\n",
    "        gloss += gan.train_on_batch(noise, yGen) #15\n",
    "    \n",
    "    dloss /= batchCount\n",
    "    gloss /= batchCount\n",
    "    print('dLoss: {:.2f}'.format(dloss))\n",
    "    print('gLoss: {:.2f}'.format(gloss))\n",
    "    #16\n",
    "    dLosses.append(dloss)\n",
    "    gLosses.append(gloss)\n",
    "    show_gen()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39b6919ff84e392c02154a19078dc43cee4f30cd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(gLosses,label='Generator Loss')\n",
    "plt.plot(dLosses, label='Discriminator Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5499c2ebc83a351298edc08b25d256dca36a3d02"
   },
   "outputs": [],
   "source": [
    "r, c = 2, 2\n",
    "noise = np.random.normal(0, 1, (r * c, 100))\n",
    "gen_imgs = generator.predict(noise)\n",
    "print(gen_imgs.shape)\n",
    "# Rescale images 0 - 1\n",
    "gen_imgs = 0.5 * gen_imgs + 1\n",
    "\n",
    "fig, axs = plt.subplots(r, c,figsize=(15,15))\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(gen_imgs[cnt, 0,:,:], cmap='gray')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "#fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "233abc0e-db93-42f0-9741-d31a0e821de9",
    "_uuid": "47a682bb7bee7a2855147e54bda1605166349b24"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
